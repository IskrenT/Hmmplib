<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Hmmplib Documentation: General Usage</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Hmmplib Documentation
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('general.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">General Usage </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#started">Getting Started</a><ul><li class="level2"><a href="#creation">Creating empty instances and manual initialization from file.</a></li>
<li class="level2"><a href="#initialization">Generalized creation and initialization from file.</a></li>
</ul>
</li>
<li class="level1"><a href="#evaluation">Evaluation</a><ul><li class="level2"><a href="#models">Evaluating multiple models against a single sequence.</a></li>
<li class="level2"><a href="#sequences">Evaluating a single model against multiple sequences.</a></li>
</ul>
</li>
<li class="level1"><a href="#decoding">Decoding</a></li>
<li class="level1"><a href="#learning">Learning</a></li>
<li class="level1"><a href="#datafilelayout">Data Layout in Memory and Files.</a><ul><li class="level2"><a href="#modelparam">Layout of data in the model parameters</a><ul><li class="level3"><a href="#initial">Initial parameters</a></li>
<li class="level3"><a href="#transition">Transition parameters</a></li>
<li class="level3"><a href="#emmision">Emission parameters</a></li>
</ul>
</li>
<li class="level2"><a href="#variablelayout">Layout of data in multi-dimentional variables</a><ul><li class="level3"><a href="#forwardvariables">Forward variables</a></li>
<li class="level3"><a href="#backwardvariables">Backward variables</a></li>
<li class="level3"><a href="#gammavariable">Baum-Welch Gamma variable</a></li>
<li class="level3"><a href="#xivariable">Baum-Welch Xi variable</a></li>
<li class="level3"><a href="#viterbivariable">Viterbi algorithm variables</a></li>
</ul>
</li>
<li class="level2"><a href="#fileformat">File format for using the file I/O interface</a><ul><li class="level3"><a href="#fileformatdata">Raw data format</a></li>
<li class="level3"><a href="#fileformatmodels">Muliple models in one file</a></li>
<li class="level3"><a href="#fileformatsequences">Multiple sequences in one file</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="started"></a>
Getting Started</h1>
<h2><a class="anchor" id="creation"></a>
Creating empty instances and manual initialization from file.</h2>
<p>The simplest way of using Hmmplib is to create instances of the models and the sequences. That can be done using the functions declared in <a class="el" href="hmmp__memop_8h.html" title="Contains memory allocation and deallocation functions for models and sequences. ">hmmp_memop.h</a>. </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__file_8h.html">hmmp_file.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__memop_8h.html">hmmp_memop.h</a>&quot;</span></div><div class="line"><span class="comment">// ...</span></div><div class="line"><a class="code" href="structs__hmmp___model.html">hmmp_Model</a> *m;</div><div class="line">m = <a class="code" href="hmmp__memop_8h.html#a7a31f981a9abeb166096ceac54819648">hmmp_create_model</a>(10,5); <span class="comment">// 10 states 5 symbols</span></div><div class="line"><a class="code" href="hmmp__file_8h.html#aa7beceb0b15d5f290850da06132eba5e">hmmp_load_real</a>(m-&gt;<a class="code" href="structs__hmmp___model.html#adb3f1ef282424b335f55fea9cd787721">initial</a>,<span class="stringliteral">&quot;initial.txt&quot;</span>,10);</div><div class="line"><a class="code" href="hmmp__file_8h.html#aa7beceb0b15d5f290850da06132eba5e">hmmp_load_real</a>(m-&gt;<a class="code" href="structs__hmmp___model.html#a3f7e095cf5eafdfc475c0acb47537f87">transition</a>,<span class="stringliteral">&quot;transition.txt&quot;</span>,10*10);</div><div class="line"><a class="code" href="hmmp__file_8h.html#aa7beceb0b15d5f290850da06132eba5e">hmmp_load_real</a>(m-&gt;<a class="code" href="structs__hmmp___model.html#a9605cc6bc68918f3836920ac6d38b546">emission</a>,<span class="stringliteral">&quot;emission.txt&quot;</span>,10*5);</div><div class="line">m-&gt;<a class="code" href="structs__hmmp___model.html#a03f0abf89f9225659091c7f83cef2928">prior</a> = 0.0;</div><div class="line">m-&gt;<a class="code" href="structs__hmmp___model.html#a6d85bd79e648642f47a8ced1bbfacd85">model_id</a> = 1;</div><div class="line"></div><div class="line"><span class="comment">// DO ACTUAL WORK</span></div><div class="line"></div><div class="line"><a class="code" href="hmmp__memop_8h.html#ac705b4c77060a194c36c355cbb081090">hmmp_delete_model</a>(m);</div></div><!-- fragment --><p> The same can be done for creating a sequence: </p><div class="fragment"><div class="line"><a class="code" href="structs__hmmp___sequence.html">hmmp_Sequence</a> *s;</div><div class="line">s = <a class="code" href="hmmp__memop_8h.html#a47c8e503e64049a99702316afe31bbcd">hmmp_create_sequence</a>(50); <span class="comment">// This sequence is 50 symbols long.</span></div><div class="line">s-&gt;<a class="code" href="structs__hmmp___sequence.html#ad03f3906ca027603299130f471bbdfe3">seq_id</a> = 1;</div><div class="line">s-&gt;<a class="code" href="structs__hmmp___sequence.html#a9f59b34b1f25fe00023291b678246bcc">length</a> = 50;</div><div class="line">s-&gt;<a class="code" href="structs__hmmp___sequence.html#a50dd1e24c50eb6cd1abe5e3a5a345bc3">cardinality</a> = 10;        <span class="comment">// The sequence has 10 distinct possible symbols.</span></div><div class="line"><a class="code" href="hmmp__file_8h.html#acdbe18604cc047f1e8fa09383ad1f186">hmmp_load_int</a>(s-&gt;<a class="code" href="structs__hmmp___sequence.html#aebc09f0a14f8844c6d13cf74d2448037">sequence</a>,<span class="stringliteral">&quot;sequence1.txt&quot;</span>,50);</div><div class="line"></div><div class="line"><span class="comment">// DO ACTUAL WORK</span></div><div class="line"></div><div class="line"><a class="code" href="hmmp__memop_8h.html#a12067e8d11316e98bb62643dfda9102e">hmmp_delete_sequence</a>(s);</div></div><!-- fragment --><p> Similarly <a class="el" href="hmmp__memop_8h.html#a6db27764427d2e74005b244cefee4433" title="Create an array of emtpy models with the same number of states and symbols. ">hmmp_create_arr_models()</a> and <a class="el" href="hmmp__memop_8h.html#adfca61e8f457c91cdcc89b10f8dd2a6b" title="Create an array of empty sequences with the same length and symbol space. ">hmmp_create_arr_seq()</a> can be used to create arrays of uninitialized models and sequences. This however is more advanced and can lead to mistakes. The recommended approach is described in the <a class="el" href="general.html#initialization">Next Subsection</a>.<br />
 The file format for simple integer or real data is just numbers separated by ' ' interval or a new line symbol '\n'.<br />
 For example transition.txt: </p><div class="fragment"><div class="line">0.3 0.6 0.1</div><div class="line">0.2 0.2 0.6</div><div class="line">0.1 0.1 0.8</div></div><!-- fragment --><p> For a detailed explaination of the data layout in memory and files check <a class="el" href="general.html#datafilelayout">Data Layout</a> </p>
<h2><a class="anchor" id="initialization"></a>
Generalized creation and initialization from file.</h2>
<p>This is the more general approach from creating and initializing models and sequences from files.<br />
 This is a safer and easier way. It also allows for storing multiple sequences or models in a single file.<br />
</p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__file_8h.html">hmmp_file.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__memop_8h.html">hmmp_memop.h</a>&quot;</span></div><div class="line"><span class="comment">// ...</span></div><div class="line"><a class="code" href="structs__hmmp___model.html">hmmp_Model</a> *models;</div><div class="line"><span class="keywordtype">int</span> num_models;</div><div class="line">num_models = <a class="code" href="hmmp__file_8h.html#a0bfe23c2165fa71c40a33d08460529fc">hmmp_load_models</a>(&amp;models, <span class="stringliteral">&quot;all_models.txt&quot;</span>,50); <span class="comment">// 50 - maximum number of models to load</span></div><div class="line"></div><div class="line"><span class="comment">// DO ACTUAL WORK</span></div><div class="line"></div><div class="line"><a class="code" href="hmmp__file_8h.html#a0a4cdcadbfe3e5f210be721af9c968f0">hmmp_save_models</a>(<span class="stringliteral">&quot;all_models_modified.txt&quot;</span>, models, num_models);</div><div class="line"><a class="code" href="hmmp__memop_8h.html#a6d86b497f10b527be1436b18c8ec349e">hmmp_delete_arr_models</a>(models, num_models);</div></div><!-- fragment --><p> Here is some example code for creating and initializing a single sequence using the generalized file method: </p><div class="fragment"><div class="line"><a class="code" href="structs__hmmp___sequence.html">hmmp_Sequence</a> *single;</div><div class="line"><a class="code" href="hmmp__file_8h.html#aca657d34fe07a1602524b2077eba39d7">hmmp_load_sequences</a>(&amp;single, <span class="stringliteral">&quot;one_sequence.txt&quot;</span>,1);</div><div class="line"></div><div class="line"><span class="comment">// DO ACTUAL WORK</span></div><div class="line"></div><div class="line"><a class="code" href="hmmp__file_8h.html#a09472274a39ec93bb283d5cb4254802d">hmmp_save_sequences</a>(<span class="stringliteral">&quot;one_sequence_modified.txt&quot;</span>, single, 1);</div><div class="line"><a class="code" href="hmmp__memop_8h.html#a12067e8d11316e98bb62643dfda9102e">hmmp_delete_sequence</a>(single);</div></div><!-- fragment --><p> The file format for multiple sequences or models can be seen <a class="el" href="general.html#fileformat">Here</a>.<br />
<br />
 <b>Note:</b><br />
 <code><a class="el" href="hmmp__file_8h.html#a0bfe23c2165fa71c40a33d08460529fc" title="Load multiple models from one file. ">hmmp_load_models()</a></code> includes creation of the models.<br />
 <code><a class="el" href="hmmp__file_8h.html#aca657d34fe07a1602524b2077eba39d7" title="Load multiple sequences from one file. ">hmmp_load_sequences()</a></code> includes creation of the sequences.<br />
 <b>After using the models and the sequences to process them with the algorithms it is recommended</b><br />
 <b>to save them back in a file and delete the array of sequences/models using the following:</b><br />
 <code><a class="el" href="hmmp__memop_8h.html#a12067e8d11316e98bb62643dfda9102e" title="Safely delete a sequence. ">hmmp_delete_sequence()</a></code><br />
 <code><a class="el" href="hmmp__memop_8h.html#a36839f20e0c37f520c36ffd5aa4dde33" title="Delete an array of previously created sequences. ">hmmp_delete_arr_seq()</a></code><br />
 <code><a class="el" href="hmmp__memop_8h.html#ac705b4c77060a194c36c355cbb081090" title="Safely delete a model. ">hmmp_delete_model()</a></code><br />
 <code><a class="el" href="hmmp__memop_8h.html#a6d86b497f10b527be1436b18c8ec349e" title="Delete an array of previously created models. ">hmmp_delete_arr_models()</a></code><br />
 <br />
<br />
 </p><hr/>
 <h1><a class="anchor" id="evaluation"></a>
Evaluation</h1>
<p>Definition: For a given model: λ=( A,B,π ) and a sequence of observable symbols O<sup>T</sup>=( o<sub>1</sub>,o<sub>2</sub>,o<sub>3</sub>,…,o<sub>T</sub> ),<br />
obtain the probability of the model <em>λ</em> to have produced the sequence <em>O<sup>T</sup></em>.<br />
In mathematical terms: <em>P(O<sup>T</sup>│λ)= ?</em></p>
<p>The evaluation is implemented using the Forward algorithm: <a class="el" href="hmmp__alg_8h.html#a14f81c6b42c91d42083c253880a9b03f" title="Execute the forward algorithm on a model and a sequence. ">hmmp_forward_alg()</a>.</p>
<p>In an active configuration for recognition there are multiple sequences and multiple models.<br />
This can be broken down to two distinct cases:<br />
</p><ul>
<li>having multiple models and a single sequence.</li>
<li>having a single model and multiple sequences.</li>
</ul>
<p>The choice of which case is appropriate for the current problem is made by the user.<br />
The examples below exibit how to use the implemented parallelism. Domain decomposition is implemented for both cases. </p>
<h2><a class="anchor" id="models"></a>
Evaluating multiple models against a single sequence.</h2>
<p>Example Usage:<br />
 <b>[The example code does not check for error code function returns. Although it might work with bad input, it is recommended to check function returns.]</b> </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__lib_8h.html">hmmp_lib.h</a>&quot;</span> <span class="comment">// Include all library headers.</span></div><div class="line"><span class="preprocessor">#include &lt;time.h&gt;</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> <a class="code" href="hmmp__datatypes_8h.html#a288864f65cbef64a54347c161a0be910">HMMP_NUM_THREADS</a> = 4; <span class="comment">//Specifying the number of threads for the task to run on.</span></div><div class="line"><span class="comment">//Optimal number of threads is equal to the number of processor cores.</span></div><div class="line"><span class="comment">// Make sure your system has OpenMP support turned ON!!!</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> evaluate_multiple_models_one_sequence()</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_OF_MODELS = 250;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_STATES = 20;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_SYMBOLS = 25;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> SEQUENCE_LEN = 1000000;</div><div class="line">    </div><div class="line">    <a class="code" href="structs__hmmp___model.html">hmmp_Model</a> *array_models;</div><div class="line">    <a class="code" href="structs__hmmp___sequence.html">hmmp_Sequence</a> *one_sequence;</div><div class="line">    <a class="code" href="hmmp__datatypes_8h.html#a3f308cafd9c0390f0966aefdd86eaed5">dbl_array</a> *log_probabilities;</div><div class="line">    </div><div class="line">    <span class="comment">//Generating random models and a random sequence.[Can be loaded from file instead.]</span></div><div class="line">    array_models = <a class="code" href="hmmp__generate_8h.html#a0dec5006094bedc90f78e8de86d224fd">hmmp_gen_random_models</a>(NUM_OF_MODELS,NUM_STATES,NUM_SYMBOLS, clock());</div><div class="line">    one_sequence = <a class="code" href="hmmp__generate_8h.html#a7be544a8943fafa793f325cbde46bdce">hmmp_gen_random_sequences</a>( 1,NUM_SYMBOLS, SEQUENCE_LEN, clock() );</div><div class="line"></div><div class="line">    <span class="comment">//Evaluating multiple models against a single sequence</span></div><div class="line">    <a class="code" href="hmmp__general_8h.html#a4fb145356f6973277b16c264b43005b8">hmmp_evaluate_models</a>(array_models,NUM_OF_MODELS, *one_sequence, &amp;log_probabilities);</div><div class="line">    </div><div class="line">    <span class="comment">//Saving the result in a file [optional]</span></div><div class="line">    <a class="code" href="hmmp__file_8h.html#a7099c8ce31f7e2faee4a72ca0c8d591c">hmmp_save_real</a>(<span class="stringliteral">&quot;result.txt&quot;</span>, log_probabilities, NUM_OF_MODELS, 1);</div><div class="line">    </div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d86b497f10b527be1436b18c8ec349e">hmmp_delete_arr_models</a>(array_models, NUM_OF_MODELS);</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a36839f20e0c37f520c36ffd5aa4dde33">hmmp_delete_arr_seq</a>(one_sequence,1);</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d5c9ddcef9c65a253e69207531cf3bf">hmmp_delete_dbl_array</a>(log_probabilities);</div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p> <b>NOTE:</b> The result is stored in a double array and represents the natural logarithm of the corresponding desired probabilies.<br />
 Logarithmic scale is used for all probability representations to prevent underflow.</p>
<h2><a class="anchor" id="sequences"></a>
Evaluating a single model against multiple sequences.</h2>
<p>Example Usage:<br />
 <b>[The example code does not check for error code function returns. Although it might work with bad input, it is recommended to check function returns.]</b> </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__lib_8h.html">hmmp_lib.h</a>&quot;</span> <span class="comment">// Include all library headers.</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> <a class="code" href="hmmp__datatypes_8h.html#a288864f65cbef64a54347c161a0be910">HMMP_NUM_THREADS</a> = 4; <span class="comment">//Specifying the number of threads for the task to run on.</span></div><div class="line"><span class="comment">//Optimal number of threads is equal to the number of processor cores.</span></div><div class="line"><span class="comment">// Make sure your system has OpenMP support turned ON!!!</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> evaluate_one_model_multiple_sequences()</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_SEQUENCES = 250;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_STATES = 20;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_SYMBOLS = 25;</div><div class="line">    <span class="comment">//const int SEQUENCE_LEN = The lengths of each sequence are described in the file;</span></div><div class="line">    <span class="keywordtype">int</span> num_seq;</div><div class="line">    </div><div class="line">    <a class="code" href="structs__hmmp___model.html">hmmp_Model</a> *one_model;</div><div class="line">    <a class="code" href="structs__hmmp___sequence.html">hmmp_Sequence</a> *arr_sequences;</div><div class="line">    <a class="code" href="hmmp__datatypes_8h.html#a3f308cafd9c0390f0966aefdd86eaed5">dbl_array</a> *log_probabilities;</div><div class="line"></div><div class="line">    <span class="comment">//Loading the model and the sequences from files. [Can be randomly generated instead.]</span></div><div class="line">    <a class="code" href="hmmp__file_8h.html#a0bfe23c2165fa71c40a33d08460529fc">hmmp_load_models</a>(&amp;one_model, <span class="stringliteral">&quot;onemodel.txt&quot;</span>, 1);</div><div class="line">    num_seq = <a class="code" href="hmmp__file_8h.html#aca657d34fe07a1602524b2077eba39d7">hmmp_load_sequences</a>(&amp;arr_sequences, <span class="stringliteral">&quot;sequences.txt&quot;</span>, NUM_SEQUENCES );</div><div class="line">    </div><div class="line">    <span class="comment">//Evaluating one model against multiple sequences</span></div><div class="line">    <a class="code" href="hmmp__general_8h.html#ae8b19e14e2a9ee4043c1ee62e943d4f1">hmmp_evaluate_sequences</a>(*one_model, arr_sequences, num_seq, &amp;log_probabilities);</div><div class="line">        </div><div class="line">    <span class="comment">//Saving the result in a file [optional]</span></div><div class="line">    <a class="code" href="hmmp__file_8h.html#a7099c8ce31f7e2faee4a72ca0c8d591c">hmmp_save_real</a>(<span class="stringliteral">&quot;result.txt&quot;</span>,log_probabilities,NUM_SEQUENCES,1);</div><div class="line">    </div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d86b497f10b527be1436b18c8ec349e">hmmp_delete_arr_models</a>(one_model, 1);</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a36839f20e0c37f520c36ffd5aa4dde33">hmmp_delete_arr_seq</a>(arr_sequences,NUM_SEQUENCES);</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d5c9ddcef9c65a253e69207531cf3bf">hmmp_delete_dbl_array</a>(log_probabilities);</div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p> <b>NOTE:</b> The result is stored in a double array and represents the natural logarithm of the corresponding desired probabilies.<br />
 Logarithmic scale is used for all probability representations to prevent underflow.</p>
<p><br />
<br />
 </p><hr/>
 <h1><a class="anchor" id="decoding"></a>
Decoding</h1>
<p>Definition: For a given model: λ=( A,B,π ) and a sequence of observable symbols O<sup>T</sup>=( o<sub>1</sub>,o<sub>2</sub>,o<sub>3</sub>,…,o<sub>T</sub> ),<br />
obtain the sequence of hidden states Q<sup>T</sup> that has the highest probability to have emitted O<sup>T</sup><br />
In mathematical terms: Q<sup>T</sup><sub>max</sub> = argmax<sub>k</sub>P(Q<sup>T</sup><sub>k</sub>|O<sup>T</sup>)</p>
<p>The decoding is implemented using the Viterbi algorithm: <a class="el" href="hmmp__alg_8h.html#a3478a87b6ee3e04b5586ddc065c4cf7c" title="Vitebri&#39;s algorithm for finding the best matching state sequence to a sequence of symbols...">hmmp_viterbi_alg()</a>. The current implementation supports multiple sequences and a single model, with domain decomposition parallelism.</p>
<p>Example usage:<br />
 <b>[The example code does not check for error code function returns. Although it might work with bad input, it is recommended to check function returns.]</b> </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__lib_8h.html">hmmp_lib.h</a>&quot;</span> <span class="comment">// Include all library headers.</span></div><div class="line"><span class="preprocessor">#include &lt;time.h&gt;</span> <span class="comment">// For random generation seed</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> HMMP_NUM_THREADS = 4; <span class="comment">//Specifying the number of threads for the task to run on.</span></div><div class="line"><span class="comment">//Optimal number of threads is equal to the number of processor cores.</span></div><div class="line"><span class="comment">// Make sure your system has OpenMP support turned ON!!!</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> decode_multiple_sequences()</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> SEQUENCE_length = 1000000;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_OF_MODELS = 1;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_OF_STATES = 25;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_OF_SYMBOLS = 20;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_OF_SEQUENCES = 24;</div><div class="line">    <a class="code" href="structs__hmmp___model.html">hmmp_Model</a> *m;</div><div class="line">    <a class="code" href="structs__hmmp___sequence.html">hmmp_Sequence</a> *obs_sequences, *state_sequences;</div><div class="line">    <a class="code" href="hmmp__datatypes_8h.html#a3f308cafd9c0390f0966aefdd86eaed5">dbl_array</a> *logP_sequences;</div><div class="line"></div><div class="line">    <span class="comment">//Generating random input data. [Can be loaded from file instead.]</span></div><div class="line">    m = <a class="code" href="hmmp__generate_8h.html#a0dec5006094bedc90f78e8de86d224fd">hmmp_gen_random_models</a> ( NUM_OF_MODELS,NUM_OF_STATES, NUM_OF_SYMBOLS, clock() );</div><div class="line">    obs_sequences = <a class="code" href="hmmp__generate_8h.html#a7be544a8943fafa793f325cbde46bdce">hmmp_gen_random_sequences</a> ( NUM_OF_SEQUENCES , NUM_OF_SYMBOLS, SEQUENCE_length, clock() );</div><div class="line">    </div><div class="line">    <span class="comment">//Decoding the sequences with the model, results in &#39;state_sequences&#39; and &#39;logP_sequences&#39;</span></div><div class="line">    <a class="code" href="hmmp__general_8h.html#abe53b2661540297d5bc74e1919c9000a">hmmp_decode</a>(*m,obs_sequences,NUM_OF_SEQUENCES,&amp;state_sequences, &amp;logP_sequences );</div><div class="line"></div><div class="line">    <span class="comment">//Saving the result in a file [optional]</span></div><div class="line">    <a class="code" href="hmmp__file_8h.html#a09472274a39ec93bb283d5cb4254802d">hmmp_save_sequences</a>(<span class="stringliteral">&quot;result_hidden_seq.txt&quot;</span>, state_sequences, NUM_OF_SEQUENCES);</div><div class="line">    <a class="code" href="hmmp__file_8h.html#a7099c8ce31f7e2faee4a72ca0c8d591c">hmmp_save_real</a>(<span class="stringliteral">&quot;correspoding_log_prob.txt&quot;</span>, logP_sequences, NUM_OF_SEQUENCES, 1);</div><div class="line">    </div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d86b497f10b527be1436b18c8ec349e">hmmp_delete_arr_models</a> ( m , NUM_OF_MODELS );</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a36839f20e0c37f520c36ffd5aa4dde33">hmmp_delete_arr_seq</a> ( obs_sequences, NUM_OF_SEQUENCES );</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a36839f20e0c37f520c36ffd5aa4dde33">hmmp_delete_arr_seq</a> ( state_sequences, NUM_OF_SEQUENCES );</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d5c9ddcef9c65a253e69207531cf3bf">hmmp_delete_dbl_array</a>( logP_sequences);</div><div class="line">}</div></div><!-- fragment --><p>For each observable sequence there is an output of a hidden state sequence and the correspoding logarithmic probability. <br />
<br />
 </p><hr/>
 <h1><a class="anchor" id="learning"></a>
Learning</h1>
<p>Definition: For a given model: λ=( A,B,π ) and a sequence of observable symbols O<sup>T</sup>=( o<sub>1</sub>,o<sub>2</sub>,o<sub>3</sub>,…,o<sub>T</sub> ),<br />
change the model parameters ( A,B,π ) to maximize the probability of the model to produce this sequence.</p>
<p>In mathematical terms: λ' = <em>f</em>( λ ,O<sup>T</sup> )= ? ,when P( λ'│O<sup>T</sup>) = max<sub>k</sub>P(λ<sub>k</sub>│O<sup>T</sup>)</p>
<p>Unfortunately there is no analytical solution to this problem. The most common method for solving the problem is the <b>Baum-Welch algorithm.</b><br />
The Baum-Welch algorithm uses EM ( Expectation Maximization ) mathematical technique.<br />
After each completed step of learning, the Baum-Welch algorithm promises: P( λ'│O<sup>T</sup>) &gt; P( λ│O<sup>T</sup>) <br />
This eventually converges to a local maximum. When training a model it is convinient to set maximum number of steps and/or minimum distance ΔP.<br />
In the example below both are used and the learning process stops when one of the conditions is satisfied.</p>
<p>The Baum-Welch algorthm can be broken down to 6 distinct sub-algorithms:</p><ol type="1">
<li><code><a class="el" href="hmmp__alg_8h.html#a14f81c6b42c91d42083c253880a9b03f" title="Execute the forward algorithm on a model and a sequence. ">hmmp_forward_alg()</a></code> - Finding forward variables. ( Scaling is applied at each "time" step to prevent underflow. )</li>
<li><code><a class="el" href="hmmp__alg_8h.html#a7758852926a707bfaba2df924d33ec0c" title="Execute the backward algorithm on a model and a sequence. ">hmmp_backward_alg()</a></code> - Finding backward variables.</li>
<li><code><a class="el" href="hmmp__alg_8h.html#a938c4143c4f76358d9329c09bedfc464" title="Execute the backward rescaling algorithm. ">hmmp_backward_rescale()</a></code> - Rescaling backward variables to use forward scaling factors. This results in easy reduction in the next steps.</li>
<li><code><a class="el" href="hmmp__alg_8h.html#ac1a3195625b12da06ba5985b6d919dfc" title="Part of the Baum-Welch algorithm: Finding the forward-backward variable ( gamma ) ...">hmmp_bwa_gamma_alg()</a></code> - Finding gamma variables.</li>
<li><code><a class="el" href="hmmp__alg_8h.html#a68be67d6896a838b0f2751c6081dc154" title="Part of the Baum-Welch algorithm: Finding the xi variables. ">hmmp_bwa_xi_alg()</a></code> - Finding xi variables.</li>
<li><code><a class="el" href="hmmp__alg_8h.html#a07726bb93d15709e982e7ac76673f924" title="Part of the Baum-Welch algorithm: Re-estimating the model parameters. ">hmmp_bwa_reest_alg()</a></code> - Using gamma and xi to find the new model parameters. The current implementation supports multiple sequences and a single model and multiple steps. The parallelism is as follows:<br />
</li>
</ol>
<p>Computation for each sequence is completed linearly ( one by one ). <em>Planning to implement domain decomposition in the future.</em></p><ul>
<li>Computation for each step is completed linearly after the previous step. <em>The algorithm doesn't allow parallelism here.</em></li>
<li>Steps 1. and 2. Are completed in parallel.</li>
<li>Step 3. requres step 1. and step.2 and is completed linearly ( lower complexity, no impact on performance )</li>
<li>Step 4. and 5. require the previous steps and are completed in parallel, containing domain decomposition within them.</li>
<li>Step 6. requres the previous steps and is completed in parallel with domain decomposition.</li>
</ul>
<p><b>NOTE:</b> The highest complexity is at step 1. and 2. as well as step 5. Since there is no domain decomposition implemented in step 1. and 2. in regard to multiple sequences, the optimal configuration for parralelism is 2 threads for step 1 and step 2,and 'number of processor cores' threads for step 4, step 5 and step 6.</p>
<p>Example usage:<br />
 <b>[The example code does not check for error code function returns. Although it might work with bad input, it is recommended to check function returns.]</b> </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="hmmp__lib_8h.html">hmmp_lib.h</a>&quot;</span> <span class="comment">// Include all library headers.</span></div><div class="line"><span class="preprocessor">#include &lt;time.h&gt;</span> <span class="comment">// For random generation seed</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> HMMP_NUM_THREADS = 2; <span class="comment">//Specifying the number of threads for the task to run on.</span></div><div class="line"><span class="comment">// Make sure your system has OpenMP support turned ON!!!</span></div><div class="line">    </div><div class="line"><span class="keywordtype">int</span> learn_example()</div><div class="line">{</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">double</span> DELTA_P = 0.001; <span class="comment">// minimum probability distance = log(Pnew/Pold)</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> MAX_STEPS = 20;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_STATES = 25;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_SYMBOLS = 25;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> NUM_SEQUENCES = 5;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> SEQ_LENGTH = 100000;</div><div class="line">            </div><div class="line">    <a class="code" href="structs__hmmp___model.html">hmmp_Model</a> *model;</div><div class="line">    <a class="code" href="structs__hmmp___sequence.html">hmmp_Sequence</a> *arr_s;</div><div class="line">    <span class="keywordtype">int</span> steps;</div><div class="line"></div><div class="line">    <span class="comment">//Generating random data. [Can be loaded from file instead.]</span></div><div class="line">    model = <a class="code" href="hmmp__generate_8h.html#a0dec5006094bedc90f78e8de86d224fd">hmmp_gen_random_models</a> ( 1,NUM_STATES,NUM_SYMBOLS, clock());</div><div class="line">    arr_s = <a class="code" href="hmmp__generate_8h.html#a7be544a8943fafa793f325cbde46bdce">hmmp_gen_random_sequences</a> (NUM_SEQUENCES,NUM_SYMBOLS,SEQ_LENGTH, clock());</div><div class="line"></div><div class="line">    <span class="comment">//Execute the Baum-Welch algorithm for learning with multiple repetition steps.     </span></div><div class="line">    steps = <a class="code" href="hmmp__general_8h.html#a365bbe8ca0c04cb1712a738f7acc820e">hmmp_baum_welch</a>(model,arr_s,NUM_SEQUENCES,MAX_STEPS,DELTA_P);</div><div class="line">            </div><div class="line">    <span class="comment">// Save the model in a file after learning. [Optional]</span></div><div class="line">    <a class="code" href="hmmp__file_8h.html#a0a4cdcadbfe3e5f210be721af9c968f0">hmmp_save_models</a>(<span class="stringliteral">&quot;manipulated_model.txt&quot;</span>, model, 1);</div><div class="line">    </div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a6d86b497f10b527be1436b18c8ec349e">hmmp_delete_arr_models</a> ( model,1 );</div><div class="line">    <a class="code" href="hmmp__memop_8h.html#a36839f20e0c37f520c36ffd5aa4dde33">hmmp_delete_arr_seq</a> ( arr_s,NUM_SEQUENCES );</div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p> The variable <code>steps</code> contains the number of steps completed while learning. <br />
It will be either equal to MAX_STEPS or lower if the probability distance function's result is lower than ΔP. </p><hr/>
 <h1><a class="anchor" id="datafilelayout"></a>
Data Layout in Memory and Files.</h1>
<p>In Hmmplib all multi-dimentional variables data is presented in a single linear array. For a proper use of the variables, parameters and files, an introduction to the chosen memory layout is required.<br />
<br />
 This section explains the data layout of the model matrices ( transition, emission ) and the model variables.<br />
 Here you can also find argumentation of why the certain layout is chosen. </p>
<h2><a class="anchor" id="modelparam"></a>
Layout of data in the model parameters</h2>
<h3><a class="anchor" id="initial"></a>
Initial parameters</h3>
<p>The model's initial parameters represent the probability of the model to begin emmision in any of the states.<br />
 If the model has <em>N</em> number of possible states, then there are <em>N</em> number of initial probabilities and they are simply stored in an array. </p>
<h3><a class="anchor" id="transition"></a>
Transition parameters</h3>
<p>The model's transition parameters represent the probabilities of the model to transition from the current state to a new state ( can be the same as the previous one ) in exactly one step ( and with exactly one emission after the transition ).<br />
 If the model has <em>N</em> number of possible states, then <b>there are <em>N*N</em> number of transition probabilities</b> ( from each state to each other state and to itself ).</p>
<p>Traditionally the transition parameters are presented in an <em>N*N</em> matrix: <b>A = {a<sub>ij</sub>}</b>. <br />
 In the program implementation they are presented linearly in an array. Each row of the matrix is layed down consequetivly in memory after the previous one. Also known as <b>Row-major layout</b>.<br />
 The index of the row <b>i</b> represents: transition from a state.<br />
 The index of the column <b>j</b> within a row represents: transition to a state.</p>
<p>Example: </p><div class="fragment"><div class="line">Number of states: 3</div><div class="line">Transition probabilities:</div><div class="line">0.05 0.1 0.85 0.15 0.2 0.65 0.4 0.4 0.2</div></div><!-- fragment --><p> <b>Note:</b> The transition probabilities within a row ( from a state ) follow the standard stochastic constraints. - add up to 1.0 <br />
 In this example the first 3 variables represent transition from the first state. The next 3 - from the second state and so on...<br />
 0.05 : from state 1 -&gt; state 1<br />
 0.85 : from state 1 -&gt; state 3<br />
 0.15 : from state 2 -&gt; state 1<br />
 0.4 : from state 3 -&gt; state 1 and state 2<br />
 0.2 : from state 2 -&gt; state 2 and from state 3 -&gt; state 3<br />
 For memory access to a particular transition parameter the following expression can be used:<br />
 <b>transition[i*N + j] = probability for transition from state 'i' to state 'j'</b><br />
 The layout for the transition parameters is chosen for convinience, it localizes the access during the backward algorithm and not during the forward algorithm. Since the backward and the forward algorithms have similar usage and both have to be executed in the Baum-Welch algorithm readability and understanding the layout is more important than the layout itself. <br />
</p>
<h3><a class="anchor" id="emmision"></a>
Emission parameters</h3>
<p>The model's emission parameters represent the probabilities of the model to emmit any of the possible symbols after making a transition.<br />
 <b>Note:</b> The emission probabilities also follow the standard stochastic constraints for each state. This means that an emission will happen after a state transition with probability 1.0.<br />
 In a discrete implementation of HMM such as Hmmplib a symbol is solely defined by its index.<br />
 If the model has <em>N</em> possible states and <em>M</em> possible symbols, then <b> there are <em>N*M</em> number of emission probabilities.</b> ( emission from each state of each symbol ).</p>
<p>Traditionally the emission parameters are presented in an <em>N*M</em> matrix: <b>B = {b<sub>jk</sub>}</b>. <br />
 Each row of the matrix is layed down consequetivly in memory after the previous one. Also known as <b>Row-major layout</b>.<br />
 The index of the row <b>j</b> represents: current state.<br />
 The index of the column <b>k</b> within a row represents: index of one of the possible symbols. </p><div class="fragment"><div class="line">Number of states: 3</div><div class="line">Number of symbols: 2</div><div class="line">Emission probabilities:</div><div class="line">0.5 0.5 0.3 0.7 0.2 0.8</div></div><!-- fragment --><p> 0.5 : from state 1 emitting symbol 1 or 2<br />
 0.3 : from state 2 emitting symbol 1<br />
 0.7 : from state 2 emitting symbol 2<br />
 0.2 : from state 3 emitting symbol 1<br />
 0.8 : from state 3 emitting symbol 2</p>
<p>For memory access to a particular emission parameter the following expression can be used:<br />
 <b>emission[j*M + k] = emission probability of symbol with index 'k' from state with index 'j'.</b><br />
 <b>Note:</b> Emission always occurs after a transition, or after choosing initial state.</p>
<h2><a class="anchor" id="variablelayout"></a>
Layout of data in multi-dimentional variables</h2>
<h3><a class="anchor" id="forwardvariables"></a>
Forward variables</h3>
<p>The forward variables are defined as:<br />
 <b>α<sub>t</sub>(i) = P( о<sub>1:t</sub>, q<sub>t</sub> = i │ λ )</b><br />
 Where:</p><ul>
<li>t - current step ( in a sequence )</li>
<li>о<sub>1:t</sub> = о<sub>1</sub>, о<sub>2</sub>, ..., о<sub>t</sub> - observed symbols in the sequence O<sup>T</sup> until the current step t.</li>
<li>q<sub>t</sub> = i - index of current state.</li>
<li>λ - the model processed against the sequence</li>
</ul>
<p>In words: <b>α<sub>t</sub>(i)</b> is the probability of the model to be in state <b>i</b> in step <b>t</b> and to have produced the symbols of the observable sequence before that.</p>
<p>Since the forward variables <b>α<sub>t</sub>(i)</b> have two indexes, they are usually placed in a matrix.</p>
<p>Every step 't' the forward variables <b>α<sub>t</sub>(i)</b> are calculated using the forward variables from the previous step <b>α<sub>t-1</sub>(i)</b>. One way to optimize the access to these variables is to provide high locality in memory.<br />
 This means that the variables in each step 't' have to be adjasent:</p>
<p>α<sub>1</sub>(1), α<sub>1</sub>(2), ..., α<sub>1</sub>(i), - the first step<br />
 α<sub>2</sub>(1), α<sub>2</sub>(2), ..., α<sub>2</sub>(i), - the second step<br />
 ..<br />
 α<sub>T</sub>(1), α<sub>T</sub>(2), ..., α<sub>T</sub>(i) - the last step</p>
<p>Traditionally the matrix is placed the opposite way in the mathematical model.<br />
 <b>Hmmplib uses a column major layout for the the forward variables in regard to states, both in memory and data files.</b></p>
<p>The index of the row <b>t</b> represents: time steps ( consequetive steps of observation ).<br />
 The index of the column <b>i</b> the state of the model for the current forward variable.</p>
<p>For memory access to a particular forward variable <b>α<sub>t</sub>(i)</b> the following expression can be used: <b>alfa[t*N + i]</b> ,when N is the number of states.</p>
<p><b>Note:</b> All forward variables use scaling to 1 at each step. This scaling accumulates since the algorithm uses the variables from the last step as an input. In order to obtain the actual values the following formula can be used:</p>
<p><b>α<sub>t</sub>(i) = ^α<sub>t</sub>(i) / ( c<sub>1</sub> * c<sub>2</sub> * ... * c<sub>t</sub> )</b><br />
 Where: α<sub>t</sub>(i) are the unscaled forward variables<br />
 ^α<sub>t</sub>(i) are the scaled forward variables<br />
 c<sub>x</sub> are the scaling values at step x</p>
<h3><a class="anchor" id="backwardvariables"></a>
Backward variables</h3>
<p>The Backward variables are defined as:<br />
 <b>β<sub>t</sub>(i) = P( о<sub>(t+1):T</sub> │ q<sub>t</sub> = i, λ )</b><br />
 Where:</p><ul>
<li>t - current step ( in a sequence )</li>
<li>о<sub>(t+1):T</sub> = о<sub>t+1</sub>, о<sub>t+2</sub> ..., о<sub>T</sub> - observed symbols in the sequence O<sup>T</sup> after the current step t.</li>
<li>q<sub>t</sub> = i - index of current state.</li>
<li>λ - the model processed against the sequence</li>
</ul>
<p>In words: <b>β<sub>t</sub>(i)</b> is the probability of the model to emit the rest of the sequence <b>о<sub>(t+1):T</sub></b>, given that the state of the model in time step <b>t</b> is <b>i</b>.</p>
<p>Similarly to the <a class="el" href="general.html#forwardvariables">Forward variables</a>, the layout of the Backward variables optimizes access with memory localization. The only difference is that the (Backward algorithm)[<a class="el" href="hmmp__alg_8h.html#a7758852926a707bfaba2df924d33ec0c">hmmp_backward_alg</a>] operates backwards through the "time" steps:</p>
<p>β<sub>1</sub>(1), β<sub>1</sub>(2), ..., β<sub>1</sub>(i), - the first step<br />
 β<sub>2</sub>(1), β<sub>2</sub>(2), ..., β<sub>2</sub>(i), - the second step<br />
 ...<br />
 β<sub>T</sub>(1), β<sub>T</sub>(2), ..., β<sub>T</sub>(i) - the last step &lt;- Algorithm starts here<br />
 Traditionally the matrix is placed the opposite way in the mathematical model. Hmmplib uses a column major layout for the the backward variables in regard to states, both in memory and data files.</p>
<p>The index of the row <b>t</b> represents: time steps ( consequetive steps of observation ).<br />
 The index of the column <b>i</b> the state of the model for the current backward variable.</p>
<p>For memory access to a particular backward variable <b>β<sub>t</sub>(i)</b> the following expression can be used: <b>beta[t*N + i]</b> ,when N is the number of states.</p>
<p><b>Note:</b> All backward variables use scaling to 1 at each step. This scaling accumulates since the algorithm uses the variables from the last step as an input. In order to obtain the actual values the following formula can be used:</p>
<p><b>β<sub>t</sub>(i) = ^β<sub>t</sub>(i) / ( d<sub>t</sub> * d<sub>t+1</sub> * ... * d<sub>T</sub> )</b><br />
 Where: β<sub>t</sub>(i) are the unscaled backward variables<br />
 ^β<sub>t</sub>(i) are the scaled backward variables<br />
 d<sub>x</sub> are the scaling values at step x</p>
<h3><a class="anchor" id="gammavariable"></a>
Baum-Welch Gamma variable</h3>
<p>The forward-backward variables or gamma variables are defined as:</p>
<p><b>γ<sub>t</sub>(i) = P( q<sub>t</sub> = i | O<sup>T</sup> , λ )</b></p>
<p>Given a sequence and a model <b>γ<sub>t</sub>(i)</b> is the probability of the model to be in state <b>i</b> at time step <b>t</b>. With conditional probabilities the equation is transformed to:</p>
<p><b>γ<sub>t</sub>(i) = ( α<sub>t</sub>(i) * β<sub>t</sub>(i) ) / P( O<sup>T</sup> │ λ )</b></p>
<p>Since the scaled forward and backward variables are used, the denominator is eliminated as it is equal to the product of the scaling factors. Only one term remains as it overlaps in both variables, that is <b>c<sub>t</sub></b> - the scaling factor at step <b>t</b>. The above formula transforms to:</p>
<p><b>γ<sub>t</sub>(i) = ^α<sub>t</sub>(i) * ^β<sub>t</sub>(i) / c<sub>t</sub></b></p>
<p>Where: ^α, ^β are the scaled variables with the same scaling factors.</p>
<p>The gamma variables are a result of computing the forward and the backward algorithms. Similarly to the <a class="el" href="general.html#forwardvariables">Forward variables</a> and the <a class="el" href="general.html#backwardvariables">Backward variables</a>, the forward-backward variables or gamma variables are layed in memory such that for one time step <b>t</b> all the variables are adjasent in regard to states <b>i</b>.</p>
<p>γ<sub>1</sub>(1), γ<sub>1</sub>(2), ..., γ<sub>1</sub>(i), - the first step<br />
 γ<sub>2</sub>(1), γ<sub>2</sub>(2), ..., γ<sub>2</sub>(i), - the second step<br />
 ...<br />
 γ<sub>T</sub>(1), γ<sub>T</sub>(2), ..., γ<sub>T</sub>(i) - the last step</p>
<p>The index of the row t represents: time steps ( consequetive steps of observation ). The index of the column i the state of the model for the current backward variable.</p>
<p>For memory access to a particular forward-backward variable <b>γ<sub>t</sub>(i)</b> the following expression can be used: <b>gamma[t*N + i]</b> ,when N is the number of states.</p>
<p><b>Note:</b> All forward-backward variables are calculated using the same scaling factors for both the forward and backward input variables. This means that before using the <a class="el" href="hmmp__alg_8h.html#ac1a3195625b12da06ba5985b6d919dfc" title="Part of the Baum-Welch algorithm: Finding the forward-backward variable ( gamma ) ...">hmmp_bwa_gamma_alg()</a> rescaling of the backward variables is neccessery using <a class="el" href="hmmp__alg_8h.html#a938c4143c4f76358d9329c09bedfc464" title="Execute the backward rescaling algorithm. ">hmmp_backward_rescale()</a>.<br />
 </p>
<h3><a class="anchor" id="xivariable"></a>
Baum-Welch Xi variable</h3>
<p>Xi variable is defined as:</p>
<p><b>ξ<sub>t</sub>(i,j) = P( q<sub>t</sub> = i , q<sub>t+1</sub> = j | O<sup>T</sup> , λ )</b></p>
<p>or the probability for the model to be in state <b>i</b> at time step <b>t</b> and in state <b>j</b> in time step <b>t+1</b>, while emitting the sequence <b>O<sup>T</sup></b>. Using conditional probabilities this equation is transformed to:</p>
<p><b>ξ<sub>t</sub>(i,j) = ( α<sub>t</sub>(i) * a<sub>ij</sub> * b<sub>jo(t+1)</sub> * β<sub>t+1</sub>(j) ) / P( O^T │ λ )</b></p>
<p>Since the scaled forward and backward variables are used the denominator is eliminated as it is equal to the product of the scaling factors. The equation simlifies to:</p>
<p><b>ξ<sub>t</sub>(i,j) = α<sub>t</sub>(i) * a<sub>ij</sub> * b<sub>jo(t+1)</sub> * β<sub>t+1</sub>(j)</b></p>
<p>The xi variable has three indices and therefore it is a three dimentional variable. In the xi variables are stored linearly in an array. The layout of the variables in memory is chosen to acommodate for access and initialization.</p><ul>
<li>The index with the smallest memory increment ( adjasent in memroy ) is: <b>t</b> - time steps.</li>
<li>The index with the medium memory increment ( T number of variables apart ) is: <b>j</b> - the state in <b>t+1</b>.</li>
<li>The index with the largest memory increment ( T*N number of variables apart ) is: <b>i</b> - the state in <b>t</b>.</li>
</ul>
<p>Visually it looks like: </p><div class="image">
<img src="baum_welch_ksi_layout.png" alt="Caption text"/>
</div>
<p>For memory access to a specific xi variable <b>ξ<sub>t</sub>(i,j)</b> the following expression can be used:<br />
 <b>xi[ i*N*T + j*N + t]</b> ,when <b>N</b> is the number of states and <b>T</b> is the length of the observed sequence.</p>
<h3><a class="anchor" id="viterbivariable"></a>
Viterbi algorithm variables</h3>
<p>The Vitebri algorithm is used for decoding, or finding a best matching sequence of states to a sequence of observable symbols.<br />
 There are three defined variables and data structures used by the algorithm. Because these variables serve a temporary role within the algorithm it is not neccessery to provide a detailed description as the algorithm can be used indirectly in <a class="el" href="hmmp__general_8h.html#abe53b2661540297d5bc74e1919c9000a" title="Use Hmmplib for decoding with a single model and multiple sequences. ">hmmp_decode()</a> and hmmp_vitebri() both provide abstraction of the implementations and memory allocation for these variables. Here is a brief explaination over each variable:</p>
<p><b>μ<sub>t</sub>(q<sub>t</sub>) = max [ P( q<sub>1:t</sub> , o<sub>1:t</sub>) ] over [ q<sub>1:(t-1)</sub> ]</b> where:</p>
<ul>
<li><b>μ<sub>t</sub>(q<sub>t</sub>)</b> - the joined probability of the partial state sequence and partial observed sequence at the most probable state in every step from step 1 to t, given the model λ and the observed sequence O<sup>T</sup>.</li>
<li><b>q<sub>t</sub></b> - the state at time step <b>t</b>.</li>
<li><b>q<sub>1:t</sub></b> = q<sub>1</sub>, q<sub>2</sub>, ..., q<sub>t</sub></li>
<li><b>o<sub>1:t</sub></b> = o<sub>1</sub>, o<sub>2</sub>, ..., o<sub>t</sub></li>
</ul>
<p>With conditional probabilities the equation is transformed to:</p>
<p><b>μ<sub>t</sub>(q<sub>t</sub>) = ( max [ ⁡μ<sub>t-1</sub>(q<sub>t-1</sub>) * а<sub>q(t-1)i</sub> ] over [ q<sub>t-1</sub> ] )* b<sub>io(t)</sub></b></p>
<p>The algorithm operates over the obvious recursion in the equation. Since the <b>μ</b> variables do not contribute to the final result only the variables at the current and the previous steps are stored in a 2xN matrix, linearly in memory.</p>
<p>At each step of the algorithm the for each state a backtracking index is stored. This index indicates what was the preceding state which lead to a maximum probability at the current state. These indices are stored in a N*T integer matrix layed consequetivly in memory.</p>
<p>At the end of the algorithm a backtracking procedure begins at the state with highest probability in the last step, recursively tracking it's predecessors. The result of the backtracking is the desired sequence of states with highest probability of emitting the observed sequence, the probability of which is stored in <br />
 <b>max<sub>qt</sub>[ μ<sub>T</sub>(q<sub>t</sub>) ]</b> </p>
<h2><a class="anchor" id="fileformat"></a>
File format for using the file I/O interface</h2>
<p>Hmmplib uses files in text format with 3 distinct ways to structure the files explained below: </p>
<h3><a class="anchor" id="fileformatdata"></a>
Raw data format</h3>
<p>Raw data is integers or real numbers stored in either scientific or regular notation. Raw data is printed in high precision 10 base scientific notation. Between each number either a new-line '\n' or a space ' ' is mandatory, this allows for visual structure, but it is ignored in the file I/O functions <a class="el" href="hmmp__file_8h.html" title="Contains all file I/O functions and stucture explanations. ">hmmp_file.h</a>.</p>
<p>Example 1 ( Structured real numbers data in scientific notation ) - Can be used for model parameters or variables. </p><div class="fragment"><div class="line">1.00000000000000010E-001 2.00000000000000010E-001 2.99999999999999990E-001 </div><div class="line">4.00000000000000020E-001 5.00000000000000000E-001 5.99999999999999980E-001 </div><div class="line">6.99999999999999960E-001 8.00000000000000040E-001 9.00000000000000020E-001 </div></div><!-- fragment --><p>Example 2 ( Data in regular notation ) - Can be used for model parameters or variables. </p><div class="fragment"><div class="line">0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0</div></div><!-- fragment --><p>Example 3 ( Integer data ) - Can be used to present observational or state sequences. </p><div class="fragment"><div class="line">1 2 3 3 5 2 1 1 4 4 3 11 3 11 4 2 2 1 4 2</div></div><!-- fragment --> <h3><a class="anchor" id="fileformatmodels"></a>
Muliple models in one file</h3>
<p>Storing multiple models in a file follows a strict file structure.</p>
<p>Example: </p><div class="fragment"><div class="line">num_models: 3</div><div class="line"></div><div class="line">model_id: 12</div><div class="line">num_states: 3</div><div class="line">num_symbols: 4</div><div class="line">prior: 0.5</div><div class="line">initial: 1 0 0 </div><div class="line">transition: 0.1 0.1 0.8 0.2 0.2 0.6 0.3 0.3 0.4</div><div class="line">emission: 0.1 0.4 0.4 0.1 0.2 0.2 0.2 0.2 0.4 0.4 0.1 0.1</div><div class="line"></div><div class="line">model_id: 15</div><div class="line">num_states: 4</div><div class="line">num_symbols: 4</div><div class="line">prior: 0.3</div><div class="line">initial: 0.5 0.4 0 0.1</div><div class="line">transition: 0.1 0.1 0.6 0.2 0.2 0.4 0.3 0.1 0.1 0.1 0.1 0.7 0.2 0.1 0.2 0.5</div><div class="line">emission:  0.1 0.4 0.4 0.1 0.2 0.2 0.2 0.2 0.4 0.4 0.1 0.1 0.2 0.2 0.1 0.5</div><div class="line"></div><div class="line">model_id: 16</div><div class="line">num_states: 4</div><div class="line">num_symbols: 4</div><div class="line">prior: 0.3</div><div class="line">initial: 4.00000000000000020E-001 5.00000000000000000E-001 0.00000000000000000E+000 1.00000000000000010E-001 </div><div class="line">transition:</div><div class="line">1.00000000000000010E-001 2.00000000000000010E-001 2.99999999999999990E-001 4.00000000000000020E-001</div><div class="line">2.00000000000000010E-001 5.99999999999999980E-001 1.00000000000000010E-001 1.00000000000000010E-001</div><div class="line">2.99999999999999990E-001 2.99999999999999990E-001 2.99999999999999990E-001 1.00000000000000010E-001</div><div class="line">2.50000000000000000E-001 2.50000000000000000E-001 2.50000000000000000E-001 2.50000000000000000E-001 </div><div class="line">emission: </div><div class="line">2.50000000000000000E-001 2.50000000000000000E-001 1.00000000000000010E-001 4.00000000000000020E-001</div><div class="line">2.00000000000000010E-001 2.00000000000000010E-001 2.00000000000000010E-001 2.00000000000000010E-001</div><div class="line">4.00000000000000020E-001 4.00000000000000020E-001 1.00000000000000010E-001 1.00000000000000010E-001</div><div class="line">1.00000000000000010E-001 2.99999999999999990E-001 2.99999999999999990E-001 1.00000000000000010E-001 </div></div><!-- fragment --><p> <b>Note:</b></p><ul>
<li>The first parameter is the number of models in the file - 'num_models'</li>
<li>There are two "\n\n" newline symbols after and before a model.</li>
<li>'prior' represents the last probability evaluated for the model.</li>
<li>The only way to distinguish models is using unique 'model_id'.</li>
</ul>
<h3><a class="anchor" id="fileformatsequences"></a>
Multiple sequences in one file</h3>
<p>Storing multiple sequences follows a similar structure to storing multiple models.</p>
<p>Example: </p><div class="fragment"><div class="line">num_sequences: 3</div><div class="line"></div><div class="line">seq_id: 1</div><div class="line">length: 11</div><div class="line">cardinality: 31</div><div class="line">sequence: 2 5 1 10 30 30 10 2 5 10 2</div><div class="line"></div><div class="line">seq_id: 2</div><div class="line">length: 9</div><div class="line">cardinality: 11</div><div class="line">sequence: 2 5 4 4 1 4 1 10 10</div><div class="line"></div><div class="line">seq_id: 3</div><div class="line">length: 13</div><div class="line">cardinality: 16</div><div class="line">sequence: 2 5 4 4 1 4 1 10 10 15 15 15 15</div></div><!-- fragment --><p><b>Note:</b></p><ul>
<li>The first parameter is the number of sequences in the file - 'num_sequences'</li>
<li>There are two "\n\n" newline symbols after and before a sequences.</li>
<li>'cardinality' represents the number of different symbols available to the sequence.</li>
<li>A symbol is defined by it's index.</li>
<li>The only way to distinguish models is using unique 'sequence_id'.</li>
</ul>
<p><br />
<br />
 </p><hr/>
 </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
